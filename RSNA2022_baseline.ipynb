{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Installations [Hidden cell]**"]},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"outputs":[],"source":["import sys\n","sys.path.append('/media/nicholasjprimiano/kerasapplications/')\n","sys.path.append('/media/nicholasjprimiano/efficientnet-keras-source-code/')\n","import keras_applications\n","import efficientnet.tfkeras as efficientnet"]},{"cell_type":"markdown","metadata":{},"source":["**Imports [Hidden cell]**"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.status.busy":"2022-07-29T07:11:03.457277Z"},"papermill":{"duration":0.012594,"end_time":"2022-07-29T08:08:59.165904","exception":false,"start_time":"2022-07-29T08:08:59.15331","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]},"source":["# RSNA - EfficientNet Baseline [TF]\n","_____\n","\n","### EfficientNet\n","\n","EfficientNet is one of the most solid baselines known today. It is a family of convolutional neural networks that have achieved state-of-the-art accuracy on ImageNet while also being smaller and faster than other models.\n","The main idea of EfficientNet is scaling up CNNs in a principled way. It uses a scalable architecture, named compound scaling, which balances network depth, width, and resolution to achieve superior performance.\n","The image below shows the scaling method in more detail.\n","\n","![](https://i.ibb.co/Y86KGDg/image4-1.png)\n","\n","#### Model Size (B5)\n","\n","As written above, the main claim of efficientnet is providing a method for scaling up neural networks. \n","Using this approach, the authors of the paper released the official efficientnet architecture scaled to various sizes [B0, B1, B2.. B7. And two monstrosities L1 and L2].\n","As it is usually empirically the case (Also hinted by the [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)): Performance increase with model size. \n","On this notebook we use the **B5** variant of efficientnet. \n","Feel free to experiment with larger sizes."]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true,"papermill":{"duration":6.216247,"end_time":"2022-07-29T08:09:05.38896","exception":false,"start_time":"2022-07-29T08:08:59.172713","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import glob\n","import traceback\n","import cv2 as cv\n","import numpy as np\n","import pandas as pd\n","from path import Path\n","from tqdm import tqdm\n","import nibabel as nib\n","import pydicom as dicom\n","import tensorflow as tf\n","from keras import layers\n","from pydicom import dcmread\n","from tensorflow import keras\n","import tensorflow_hub as hub\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import backend as K\n","from pydicom.data import get_testdata_files\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import StratifiedKFold\n","from pydicom.pixel_data_handlers.util import apply_voi_lut\n","from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array"]},{"cell_type":"markdown","metadata":{},"source":["### Data Loading\n","\n","> **Note:** Mean target calculation for a baseline submission."]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-output":true,"papermill":{"duration":0.024756,"end_time":"2022-07-29T08:09:05.420496","exception":false,"start_time":"2022-07-29T08:09:05.39574","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_15427/167522624.py:1: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  bad = np.array([['1.2.826.0.1.3680043.10197_C1', '1.2.826.0.1.3680043.10197','C1'],['1.2.826.0.1.3680043.10454_C1', '1.2.826.0.1.3680043.10454','C1'],['1.2.826.0.1.3680043.10690_C1', '1.2.826.0.1.3680043.10690','C1']], dtype=np.object)\n"]}],"source":["bad = np.array([['1.2.826.0.1.3680043.10197_C1', '1.2.826.0.1.3680043.10197','C1'],['1.2.826.0.1.3680043.10454_C1', '1.2.826.0.1.3680043.10454','C1'],['1.2.826.0.1.3680043.10690_C1', '1.2.826.0.1.3680043.10690','C1']], dtype=object)\n","\n","train_df = pd.read_csv(\"/media/nicholasjprimiano/rsna-2022-cervical-spine-fracture-detection/train.csv\")\n","test_df = pd.read_csv(\"/media/nicholasjprimiano/rsna-2022-cervical-spine-fracture-detection/test.csv\")\n","\n","train_dir = '/media/nicholasjprimiano/rsna-2022-cervical-spine-fracture-detection/train_images'\n","test_dir = '/media/nicholasjprimiano/rsna-2022-cervical-spine-fracture-detection/test_images'\n","first_image = os.path.join(test_dir, test_df['StudyInstanceUID'].iloc[0])\n","\n","new_submission = []\n","means = train_df.median(numeric_only=True).to_dict()\n","means = dict(zip(train_df.columns[1:], np.average(train_df[train_df.columns[1:]], axis=0, weights=train_df[\"patient_overall\"] + 1)))\n","prediction_type = test_df['prediction_type'].tolist()\n","submission = pd.read_csv('/media/nicholasjprimiano/rsna-2022-cervical-spine-fracture-detection/sample_submission.csv')\n","for i in range(len(submission)):        \n","    new_submission.append(means[prediction_type[i]])\n","submission['fractured'] = new_submission\n","\n","\n","if(test_df.values[0][0] == bad[0][0]): test_df = pd.DataFrame({\"row_id\": ['1.2.826.0.1.3680043.22327_C1', '1.2.826.0.1.3680043.25399_C1', '1.2.826.0.1.3680043.5876_C1'], \"StudyInstanceUID\": ['1.2.826.0.1.3680043.22327', '1.2.826.0.1.3680043.25399', '1.2.826.0.1.3680043.5876'], \"prediction_type\": [\"C1\", \"C1\", \"C1\"]})  \n","prediction_type_mapping = test_df['prediction_type'].map({'C1': 0, 'C2': 1, 'C3': 2, 'C4': 3, 'C5': 4, 'C6': 5, 'C7': 6}).values"]},{"cell_type":"markdown","metadata":{},"source":["#### Utility Functions & Variables\n","\n","- **load_dicom:** For loading (and converting) a single dicom image.\n","- **lisdirs:** For listing the data directory.\n","- **train_dir / test_dir:** used later on for fast switching between train & validation paths"]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-output":true,"papermill":{"duration":0.16032,"end_time":"2022-07-29T08:09:05.627583","exception":false,"start_time":"2022-07-29T08:09:05.467263","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["def load_dicom(path, size = 64):\n","    try:\n","        img=dicom.dcmread(path)\n","        img.PhotometricInterpretation = 'YBR_FULL'\n","        data=img.pixel_array\n","        data=data-np.min(data)\n","        if np.max(data) != 0:\n","            data=data/np.max(data)\n","        data=(data*255).astype(np.uint8)        \n","        return cv2.cvtColor(data.reshape(512, 512), cv2.COLOR_GRAY2RGB)\n","    except:        \n","        return np.zeros((512, 512, 3))\n","\n","def listdirs(folder):\n","    return [d for d in os.listdir(folder) if os.path.isdir(os.path.join(folder, d))]    \n","\n","train_dir = '/media/nicholasjprimiano/rsna-2022-cervical-spine-fracture-detection/train_images'\n","test_dir = '/media/nicholasjprimiano/rsna-2022-cervical-spine-fracture-detection/test_images'\n","patients = sorted(os.listdir(train_dir))"]},{"cell_type":"markdown","metadata":{},"source":["#### Quick Visualizations\n","\n","> **Credit:** This great [notebook](https://www.kaggle.com/code/realneuralnetwork/rsna-efficientnet-infer) by [Kabir Ivan](https://www.kaggle.com/realneuralnetwork)\n","\n","Simple sanity test - mainly for testing out the load_dicom function.load_dicom"]},{"cell_type":"markdown","metadata":{},"source":["**Training Samples**"]},{"cell_type":"code","execution_count":5,"metadata":{"papermill":{"duration":2.149725,"end_time":"2022-07-29T08:09:07.893373","exception":false,"start_time":"2022-07-29T08:09:05.743648","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["'image_file = glob.glob(\"/media/nicholasjprimiano/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.10001/*.dcm\")\\nplt.figure(figsize=(20, 20))\\n\\nfor i in range(28):\\n    ax = plt.subplot(7, 7, i + 1)\\n    image_path = image_file[i]\\n    image = load_dicom(image_path)\\n    plt.axis(\\'off\\')   \\n    plt.imshow(image)'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"image_file = glob.glob(\"/media/nicholasjprimiano/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.10001/*.dcm\")\n","plt.figure(figsize=(20, 20))\n","\n","for i in range(28):\n","    ax = plt.subplot(7, 7, i + 1)\n","    image_path = image_file[i]\n","    image = load_dicom(image_path)\n","    plt.axis('off')   \n","    plt.imshow(image)\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["**Targets**"]},{"cell_type":"code","execution_count":6,"metadata":{"papermill":{"duration":30.694147,"end_time":"2022-07-29T08:09:38.606222","exception":false,"start_time":"2022-07-29T08:09:07.912075","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["'image_file = glob.glob(\"/media/nicholasjprimiano/rsna-2022-cervical-spine-fracture-detection/segmentations/*.nii\")\\nplt.figure(figsize=(20, 20))\\n\\nfor i in range(28):\\n    ax = plt.subplot(7, 7, i + 1)\\n    image_path = image_file[i]\\n    nii_img = nib.load(image_path).get_fdata()\\n    nib_image = nii_img[:,:,59]\\n    plt.axis(\\'off\\')\\n    plt.imshow(nib_image)'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"image_file = glob.glob(\"/media/nicholasjprimiano/rsna-2022-cervical-spine-fracture-detection/segmentations/*.nii\")\n","plt.figure(figsize=(20, 20))\n","\n","for i in range(28):\n","    ax = plt.subplot(7, 7, i + 1)\n","    image_path = image_file[i]\n","    nii_img = nib.load(image_path).get_fdata()\n","    nib_image = nii_img[:,:,59]\n","    plt.axis('off')\n","    plt.imshow(nib_image)\"\"\""]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.019352,"end_time":"2022-07-29T08:09:38.644788","exception":false,"start_time":"2022-07-29T08:09:38.625436","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]},"source":["### Data Generators\n","\n","Since the training data can be a bit large, we load it batch by batch when training & inference.\n","This is done through simple keras generators. "]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.019352,"end_time":"2022-07-29T08:09:38.644788","exception":false,"start_time":"2022-07-29T08:09:38.625436","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]},"source":["#### Train Generator \n","\n","- Also yields labels"]},{"cell_type":"code","execution_count":7,"metadata":{"_kg_hide-output":true,"papermill":{"duration":43.834223,"end_time":"2022-07-29T08:10:22.498796","exception":false,"start_time":"2022-07-29T08:09:38.664573","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["def RSNATrainGenerator(train_df, batch_size=64, infinite = True, base_path = train_dir):\n","    while True:\n","        trainset = []\n","        trainidt = []\n","        trainlabel = []\n","        for i in (range(len(train_df))):\n","            idt = train_df.loc[i, 'StudyInstanceUID']\n","            path = os.path.join(train_dir, idt)\n","            for im in os.listdir(path):\n","                dc = dicom.read_file(os.path.join(path,im))\n","                if dc.file_meta.TransferSyntaxUID.name =='JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])':\n","                    continue\n","                img = load_dicom(os.path.join(path , im))\n","                img = cv.resize(img, (128 , 128))\n","                image = img_to_array(img)\n","                image = image / 255.0\n","                trainset += [image]\n","                cur_label = []\n","                cur_label.append(train_df.loc[i,'C1'])\n","                cur_label.append(train_df.loc[i,'C2'])\n","                cur_label.append(train_df.loc[i,'C3'])\n","                cur_label.append(train_df.loc[i,'C4'])\n","                cur_label.append(train_df.loc[i,'C5'])\n","                cur_label.append(train_df.loc[i,'C6'])\n","                cur_label.append(train_df.loc[i,'C7'])\n","                trainlabel += [cur_label]\n","                trainidt += [idt]\n","                if len(trainidt) == batch_size:                    \n","                    yield np.array(trainset), np.array(trainlabel)\n","                    trainset, trainlabel, trainidt = [], [], []\n","            i+=1"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T17:42:19.010626Z","iopub.status.busy":"2022-09-10T17:42:19.010203Z","iopub.status.idle":"2022-09-10T17:42:19.222250Z","shell.execute_reply":"2022-09-10T17:42:19.221264Z","shell.execute_reply.started":"2022-09-10T17:42:19.010588Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\nimg, label = next(RSNATrainGenerator(train_df, batch_size=12, infinite = True, base_path = train_dir))\\nplt.imshow(img[0,:,:,:])\\nprint(img.shape)\\nprint(label.shape)'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","img, label = next(RSNATrainGenerator(train_df, batch_size=12, infinite = True, base_path = train_dir))\n","plt.imshow(img[0,:,:,:])\n","print(img.shape)\n","print(label.shape)\"\"\""]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["\"count = 0\\nbatch_size = 2\\nreturn_vals = ()\\nwhile count < 2:\\n    trainset = []\\n    trainidt = []\\n    trainlabel = []\\n    for i in (range(len(train_df))):\\n        idt = train_df.loc[i, 'StudyInstanceUID']\\n        path = os.path.join(train_dir, idt)\\n        for im in os.listdir(path):\\n            dc = dicom.read_file(os.path.join(path,im))\\n            if dc.file_meta.TransferSyntaxUID.name =='JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])':\\n                continue\\n            img = load_dicom(os.path.join(path , im))\\n            img = cv.resize(img, (128 , 128))\\n            image = img_to_array(img)\\n            plt.imshow(image)\\n            image = image / 255.0\\n            trainset += [image]\\n            cur_label = []\\n            cur_label.append(train_df.loc[i,'C1'])\\n            cur_label.append(train_df.loc[i,'C2'])\\n            cur_label.append(train_df.loc[i,'C3'])\\n            cur_label.append(train_df.loc[i,'C4'])\\n            cur_label.append(train_df.loc[i,'C5'])\\n            cur_label.append(train_df.loc[i,'C6'])\\n            cur_label.append(train_df.loc[i,'C7'])\\n            trainlabel += [cur_label]\\n            trainidt += [idt]\\n            if len(trainidt) == batch_size:                    \\n                return_vals = np.array(trainset), np.array(trainlabel)\\n                trainset, trainlabel, trainidt = [], [], []\\n        i+=1\\n        count+=1\""]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"count = 0\n","batch_size = 2\n","return_vals = ()\n","while count < 2:\n","    trainset = []\n","    trainidt = []\n","    trainlabel = []\n","    for i in (range(len(train_df))):\n","        idt = train_df.loc[i, 'StudyInstanceUID']\n","        path = os.path.join(train_dir, idt)\n","        for im in os.listdir(path):\n","            dc = dicom.read_file(os.path.join(path,im))\n","            if dc.file_meta.TransferSyntaxUID.name =='JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])':\n","                continue\n","            img = load_dicom(os.path.join(path , im))\n","            img = cv.resize(img, (128 , 128))\n","            image = img_to_array(img)\n","            plt.imshow(image)\n","            image = image / 255.0\n","            trainset += [image]\n","            cur_label = []\n","            cur_label.append(train_df.loc[i,'C1'])\n","            cur_label.append(train_df.loc[i,'C2'])\n","            cur_label.append(train_df.loc[i,'C3'])\n","            cur_label.append(train_df.loc[i,'C4'])\n","            cur_label.append(train_df.loc[i,'C5'])\n","            cur_label.append(train_df.loc[i,'C6'])\n","            cur_label.append(train_df.loc[i,'C7'])\n","            trainlabel += [cur_label]\n","            trainidt += [idt]\n","            if len(trainidt) == batch_size:                    \n","                return_vals = np.array(trainset), np.array(trainlabel)\n","                trainset, trainlabel, trainidt = [], [], []\n","        i+=1\n","        count+=1\"\"\""]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'path = os.path.join(train_dir, idt)\\n\\nim = os.listdir(path)\\n\\n#print(im)\\n\\ndc = dicom.read_file(os.path.join(path,im[10]))\\n\\n#print(dc.file_meta.TransferSyntaxUID.name)\\n\\nimg = load_dicom(os.path.join(path , im[10]))\\n\\nimg = cv.resize(img, (128 , 128))\\n\\nimage = img_to_array(img)\\n\\nplt.imshow(image)\\nimage = image / 255.0\\n\\nplt.imshow(image)\\n\\nprint(len([image]))'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"path = os.path.join(train_dir, idt)\n","\n","im = os.listdir(path)\n","\n","#print(im)\n","\n","dc = dicom.read_file(os.path.join(path,im[10]))\n","\n","#print(dc.file_meta.TransferSyntaxUID.name)\n","\n","img = load_dicom(os.path.join(path , im[10]))\n","\n","img = cv.resize(img, (128 , 128))\n","\n","image = img_to_array(img)\n","\n","plt.imshow(image)\n","image = image / 255.0\n","\n","plt.imshow(image)\n","\n","print(len([image]))\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["#### Test Generator\n","\n","- Yields only image samples"]},{"cell_type":"code","execution_count":11,"metadata":{"_kg_hide-output":true,"papermill":{"duration":0.027741,"end_time":"2022-07-29T08:10:22.619265","exception":false,"start_time":"2022-07-29T08:10:22.591524","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["def RSNATestGenerator(test_df, batch_size, infinite = True, base_path = test_dir):\n","    while 1:        \n","        testset=[]\n","        testidt=[]\n","        for i in (range(len(test_df))):        \n","            if type(test_df) is list: idt = test_df[i]\n","            else: idt = test_df['StudyInstanceUID'].iloc[i]\n","            path = os.path.join(base_path, idt)\n","            if os.path.exists(path):\n","                for im in os.listdir(path):\n","                    dc = dicom.read_file(os.path.join(path,im))\n","                    if dc.file_meta.TransferSyntaxUID.name =='JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])':\n","                        continue\n","                    img=load_dicom(os.path.join(path,im))\n","                    img=cv.resize(img,(128, 128))\n","                    image=img_to_array(img)\n","                    image=image/255.0\n","                    testset+=[image]\n","                    testidt+=[idt]\n","                    if len(testset) == batch_size:                        \n","                        yield np.array(testset)\n","                        testset = []\n","        if len(testset) > 0: yield np.array(testset)\n","        if not infinite: break"]},{"cell_type":"markdown","metadata":{},"source":["#### The Model\n","\n","> **Note:** The training data loads as a single channel image, we use a simple `Conv2D` to align it to be a 3 channel image (As expected by efficientnet)."]},{"cell_type":"code","execution_count":30,"metadata":{"_kg_hide-output":true,"papermill":{"duration":3.057017,"end_time":"2022-07-29T08:10:39.750905","exception":false,"start_time":"2022-07-29T08:10:36.693888","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, None, None, 1)]   0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, None, None, 3)     30        \n","                                                                 \n"," resnet152v2 (Functional)    (None, None, None, 2048)  58331648  \n","                                                                 \n"," global_average_pooling2d (G  (None, 2048)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 7)                 14343     \n","                                                                 \n","=================================================================\n","Total params: 58,346,021\n","Trainable params: 58,202,277\n","Non-trainable params: 143,744\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.applications import ResNet152V2\n","\n","def get_model():\n","    inp = keras.layers.Input((None, None ,1))\n","    x = Conv2D(3, 3, padding = 'SAME')(inp)\n","    #x = efficientnet.EfficientNetB5(include_top=False, weights='/media/nicholasjprimiano/efficientnet-b5_advprop_notop.h5')(x)\n","    x = ResNet152V2(include_top=False)(x)\n","    x = keras.layers.GlobalAveragePooling2D()(x)\n","    out = keras.layers.Dense(7, 'sigmoid')(x)\n","    model = keras.models.Model(inp, out)\n","    model.summary()\n","    model.compile(loss=\"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001), metrics = ['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n","    return model\n","\n","model = get_model()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'def get_model(width=128, height=128, depth=64):\\n    #Build a 3D convolutional neural network model.\\n\\n    inputs = keras.layers.Input((128, 128, 64, 1))\\n\\n    x = layers.Conv3D(filters=64, kernel_size=2, activation=\"relu\")(inputs)\\n    #x = layers.MaxPool3D(pool_size=2)(x)\\n    x = layers.BatchNormalization()(x)\\n\\n    #x = layers.Conv3D(filters=64, kernel_size=2, activation=\"relu\")(x)\\n    #x = layers.MaxPool3D(pool_size=2)(x)\\n    #x = layers.BatchNormalization()(x)\\n\\n    x = layers.Conv3D(filters=128, kernel_size=2, activation=\"relu\")(x)\\n    #x = layers.MaxPool3D(pool_size=2)(x)\\n    x = layers.BatchNormalization()(x)\\n    \\n    x = layers.Conv3D(filters=256, kernel_size=1, activation=\"relu\")(x)\\n    #x = layers.MaxPool3D(pool_size=2)(x)\\n    x = layers.BatchNormalization()(x)\\n\\n    x = layers.GlobalAveragePooling3D()(x)\\n    x = layers.Dense(units=512, activation=\"relu\")(x)\\n    x = layers.Dropout(0.3)(x)\\n\\n    out = keras.layers.Dense(7, \\'sigmoid\\')(x)\\n    model = keras.models.Model(inputs, out)\\n    return model\\n\\n# Build model.\\nmodel = get_model(width=128, height=128, depth=64)\\nmodel.summary()\\n\\n# Compile model.\\ninitial_learning_rate = 0.0001\\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\\ninitial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True)\\n\\nmodel.compile(\\nloss=\"binary_crossentropy\",\\noptimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\\nmetrics=[\"acc\"],)'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"def get_model(width=128, height=128, depth=64):\n","    #Build a 3D convolutional neural network model.\n","\n","    inputs = keras.layers.Input((128, 128, 64, 1))\n","\n","    x = layers.Conv3D(filters=64, kernel_size=2, activation=\"relu\")(inputs)\n","    #x = layers.MaxPool3D(pool_size=2)(x)\n","    x = layers.BatchNormalization()(x)\n","\n","    #x = layers.Conv3D(filters=64, kernel_size=2, activation=\"relu\")(x)\n","    #x = layers.MaxPool3D(pool_size=2)(x)\n","    #x = layers.BatchNormalization()(x)\n","\n","    x = layers.Conv3D(filters=128, kernel_size=2, activation=\"relu\")(x)\n","    #x = layers.MaxPool3D(pool_size=2)(x)\n","    x = layers.BatchNormalization()(x)\n","    \n","    x = layers.Conv3D(filters=256, kernel_size=1, activation=\"relu\")(x)\n","    #x = layers.MaxPool3D(pool_size=2)(x)\n","    x = layers.BatchNormalization()(x)\n","\n","    x = layers.GlobalAveragePooling3D()(x)\n","    x = layers.Dense(units=512, activation=\"relu\")(x)\n","    x = layers.Dropout(0.3)(x)\n","\n","    out = keras.layers.Dense(7, 'sigmoid')(x)\n","    model = keras.models.Model(inputs, out)\n","    return model\n","\n","# Build model.\n","model = get_model(width=128, height=128, depth=64)\n","model.summary()\n","\n","# Compile model.\n","initial_learning_rate = 0.0001\n","lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n","initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True)\n","\n","model.compile(\n","loss=\"binary_crossentropy\",\n","optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n","metrics=[\"acc\"],)\"\"\"\n","\"\"\"tf.keras.utils.plot_model(model, show_shapes=True)\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["#### Main Training Cell\n","\n","We use a stratified (based on patient_overall) KFold split and train 5 different models. "]},{"cell_type":"code","execution_count":31,"metadata":{"papermill":{"duration":12.626652,"end_time":"2022-07-29T08:10:53.671194","exception":false,"start_time":"2022-07-29T08:10:41.044542","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","25/25 [==============================] - 14s 272ms/step - loss: 0.1904 - accuracy: 0.1169 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.7618 - val_accuracy: 0.0000e+00 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 2/50\n","25/25 [==============================] - 6s 227ms/step - loss: 0.1355 - accuracy: 0.1912 - auc: 0.6770 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.6878 - val_accuracy: 0.0000e+00 - val_auc: 0.4978 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 3/50\n","25/25 [==============================] - 5s 210ms/step - loss: 0.3635 - accuracy: 0.0994 - auc: 0.7937 - precision: 0.4586 - recall: 0.3600 - val_loss: 4.5515 - val_accuracy: 0.0000e+00 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 4/50\n","25/25 [==============================] - 5s 214ms/step - loss: 0.2617 - accuracy: 0.2000 - auc: 0.8002 - precision: 0.6078 - recall: 0.2868 - val_loss: 0.9078 - val_accuracy: 0.0000e+00 - val_auc: 0.6094 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 5/50\n","25/25 [==============================] - 5s 214ms/step - loss: 0.3084 - accuracy: 0.3187 - auc: 0.8751 - precision: 0.7114 - recall: 0.6510 - val_loss: 0.0669 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 6/50\n","25/25 [==============================] - 5s 211ms/step - loss: 0.4645 - accuracy: 0.4344 - auc: 0.7748 - precision: 0.5156 - recall: 0.4058 - val_loss: 0.3794 - val_accuracy: 0.3047 - val_auc: 0.2750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 7/50\n","25/25 [==============================] - 6s 228ms/step - loss: 0.2619 - accuracy: 0.1213 - auc: 0.7866 - precision: 0.0303 - recall: 0.0010 - val_loss: 0.9387 - val_accuracy: 0.0000e+00 - val_auc: 0.2999 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 1/50\n","25/25 [==============================] - 9s 259ms/step - loss: 0.4360 - accuracy: 0.3644 - auc: 0.8110 - precision: 0.5102 - recall: 0.3942 - val_loss: 0.0450 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 2/50\n","25/25 [==============================] - 5s 210ms/step - loss: 0.2989 - accuracy: 0.2656 - auc: 0.7272 - precision: 0.3783 - recall: 0.3174 - val_loss: 0.3007 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 3/50\n","25/25 [==============================] - 5s 213ms/step - loss: 0.3786 - accuracy: 0.2319 - auc: 0.6770 - precision: 0.1781 - recall: 0.1600 - val_loss: 3.5396e-05 - val_accuracy: 0.0052 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 4/50\n","25/25 [==============================] - 5s 215ms/step - loss: 0.4569 - accuracy: 0.5169 - auc: 0.5740 - precision: 0.5230 - recall: 0.2011 - val_loss: 0.0584 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 5/50\n","25/25 [==============================] - 6s 233ms/step - loss: 0.4192 - accuracy: 0.5294 - auc: 0.8598 - precision: 0.8157 - recall: 0.6647 - val_loss: 0.3645 - val_accuracy: 0.0000e+00 - val_auc: 0.4810 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"]},{"name":"stderr","output_type":"stream","text":["2022-09-11 09:34:04.862170: W tensorflow/core/framework/op_kernel.cc:1733] INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_74 in the registry.\n","Traceback (most recent call last):\n","\n","  File \"/home/nicholasjprimiano/.local/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 263, in __call__\n","    raise ValueError(f\"Could not find callback with key={token} in the \"\n","\n","ValueError: Could not find callback with key=pyfunc_74 in the registry.\n","\n","\n","2022-09-11 09:34:04.862220: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_74 in the registry.\n","Traceback (most recent call last):\n","\n","  File \"/home/nicholasjprimiano/.local/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 263, in __call__\n","    raise ValueError(f\"Could not find callback with key={token} in the \"\n","\n","ValueError: Could not find callback with key=pyfunc_74 in the registry.\n","\n","\n","\t [[{{node PyFunc}}]]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","25/25 [==============================] - 9s 259ms/step - loss: 0.4112 - accuracy: 0.3594 - auc: 0.7866 - precision: 0.5115 - recall: 0.3158 - val_loss: 0.0599 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 2/50\n","25/25 [==============================] - 5s 209ms/step - loss: 0.2463 - accuracy: 0.3181 - auc: 0.8364 - precision: 0.4296 - recall: 0.3452 - val_loss: 0.3634 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 3/50\n","25/25 [==============================] - 5s 214ms/step - loss: 0.2877 - accuracy: 0.2812 - auc: 0.7872 - precision: 0.4288 - recall: 0.3096 - val_loss: 0.1367 - val_accuracy: 0.2318 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 1/50\n","25/25 [==============================] - 9s 253ms/step - loss: 0.4692 - accuracy: 0.3963 - auc: 0.7437 - precision: 0.3644 - recall: 0.2384 - val_loss: 0.0857 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 2/50\n","25/25 [==============================] - 5s 211ms/step - loss: 0.2566 - accuracy: 0.3556 - auc: 0.7823 - precision: 0.4794 - recall: 0.3740 - val_loss: 0.0744 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 3/50\n","25/25 [==============================] - 5s 207ms/step - loss: 0.3005 - accuracy: 0.2519 - auc: 0.7840 - precision: 0.1631 - recall: 0.0992 - val_loss: 0.0895 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 4/50\n","25/25 [==============================] - 5s 216ms/step - loss: 0.3652 - accuracy: 0.4519 - auc: 0.7177 - precision: 0.5851 - recall: 0.3845 - val_loss: 0.0300 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 5/50\n","25/25 [==============================] - 5s 213ms/step - loss: 0.4778 - accuracy: 0.5775 - auc: 0.8537 - precision: 0.8507 - recall: 0.5084 - val_loss: 2.0157 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 6/50\n","25/25 [==============================] - 6s 225ms/step - loss: 0.4196 - accuracy: 0.1619 - auc: 0.6955 - precision: 0.1095 - recall: 0.1127 - val_loss: 0.2941 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 1/50\n","25/25 [==============================] - 8s 248ms/step - loss: 0.4521 - accuracy: 0.4944 - auc: 0.7933 - precision: 0.5052 - recall: 0.2811 - val_loss: 0.8110 - val_accuracy: 0.0000e+00 - val_auc: 0.6735 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 2/50\n","25/25 [==============================] - 6s 224ms/step - loss: 0.2792 - accuracy: 0.2881 - auc: 0.7114 - precision: 0.3846 - recall: 0.1387 - val_loss: 0.7081 - val_accuracy: 0.0469 - val_auc: 0.1548 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 3/50\n","25/25 [==============================] - 5s 213ms/step - loss: 0.3397 - accuracy: 0.3069 - auc: 0.6971 - precision: 0.0584 - recall: 0.0318 - val_loss: 0.2894 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.8229\n","Epoch 4/50\n","25/25 [==============================] - 5s 217ms/step - loss: 0.3640 - accuracy: 0.3638 - auc: 0.7020 - precision: 0.4910 - recall: 0.2795 - val_loss: 0.1661 - val_accuracy: 0.1354 - val_auc: 0.9133 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 5/50\n","25/25 [==============================] - 6s 223ms/step - loss: 0.4802 - accuracy: 0.3519 - auc: 0.8504 - precision: 0.7959 - recall: 0.4525 - val_loss: 0.6220 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 6/50\n","25/25 [==============================] - 5s 222ms/step - loss: 0.3270 - accuracy: 0.2681 - auc: 0.8302 - precision: 0.3880 - recall: 0.2793 - val_loss: 5.5033 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"]}],"source":["for train_idx, val_idx in StratifiedKFold(5).split(train_df, train_df['patient_overall']):    \n","    K.clear_session()\n","    x_train = train_df.iloc[train_idx].reset_index()\n","    x_val = train_df.iloc[val_idx].reset_index()\n","\n","    hist = model.fit(                            \n","                                    RSNATrainGenerator(x_train, min(len(x_train), 64), infinite = False, base_path = train_dir),\n","                                    epochs = 50,\n","                                    verbose = 1,\n","                                    callbacks = [keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 2, restore_best_weights = True)],\n","                                    validation_steps = max((len(x_val) // 64), 1),\n","                                    steps_per_epoch = max((len(x_train) // 64), 1),\n","                                    validation_data = RSNATrainGenerator(x_val, min(len(x_val), 64), infinite = False, base_path = train_dir),\n","                              )\n"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["val_pred = model.predict(RSNATestGenerator(x_val, min(len(test_df), 64), infinite = False, base_path = train_dir), steps = max((len(test_df) // 64), 1))    \n","try: # the best we can do at the moment..\n","    preds = model.predict(RSNATestGenerator(test_df, min(len(test_df), 64), infinite = False, base_path = test_dir), steps = max((len(test_df) // 64), 1))\n","    new_preds = []\n","    for pred_idx in range(len(preds)):\n","        new_preds.append(preds[pred_idx][prediction_type_mapping[pred_idx]])\n","    # submission['fractured'] += preds[:, prediction_type_mapping] / 5\n","    submission['fractured'] += np.array(new_preds) / 5      \n","except: traceback.print_exc()   "]},{"cell_type":"markdown","metadata":{},"source":["#### Submission"]},{"cell_type":"code","execution_count":18,"metadata":{"papermill":{"duration":0.040295,"end_time":"2022-07-29T08:11:02.989344","exception":false,"start_time":"2022-07-29T08:11:02.949049","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["\"submission\\nsubmission.to_csv('submission.csv', index = 0)\""]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"submission\n","submission.to_csv('submission.csv', index = 0)\"\"\""]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"b04e7af602e0a8fa6ea1382195bf7179f94ca3ab1b8167449e2de675db04145a"}}},"nbformat":4,"nbformat_minor":4}
